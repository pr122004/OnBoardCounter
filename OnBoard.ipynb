{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1dlPmsEEIEWgdrXXgCjgL5lsxt6hZtYpG",
      "authorship_tag": "ABX9TyNz8bGZvZxKvK8LPgAfysbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pr122004/OnBoardCounter/blob/main/OnBoard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/pr122004/OnBoardCounter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8pzIYGl1aRb",
        "outputId": "d9b52890-40c8-4f56-db39-a18ab4613a87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OnBoardCounter'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 44 (delta 1), reused 9 (delta 1), pack-reused 30\u001b[K\n",
            "Receiving objects: 100% (44/44), 131.13 MiB | 12.11 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bipSB5Lm3iXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a0ea63-45d1-4bbe-d140-b2d1a51180be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "oO5jTDPm4oSy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to run python file Classification.py in colab notebook\n",
        "\n",
        "%cd OnBoardCounter\n",
        "!python Classification.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-B4wNAW4o2a",
        "outputId": "f9738d35-46c3-400e-b3a4-00bdfe19373d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'OnBoardCounter'\n",
            "/content/OnBoardCounter\n",
            "2024-05-31 04:56:31.585669: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-31 04:56:31.585722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-31 04:56:31.587673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-31 04:56:31.599217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-31 04:56:33.064091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-05-31 04:56:40.719653: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.769886: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.770208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.771006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.771284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.771538: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.859895: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.860437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.860663: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-05-31 04:56:40.860902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 04:56:40.861109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Epoch 1/50\n",
            "2024-05-31 04:56:44.264109: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
            "2024-05-31 04:56:53.160084: I external/local_xla/xla/service/service.cc:168] XLA service 0x7a43d0795b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-05-31 04:56:53.160134: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2024-05-31 04:56:53.166739: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1717131413.267569   28263 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "17/17 [==============================] - 22s 616ms/step - loss: 11.6459 - accuracy: 0.4945 - val_loss: 7.9475 - val_accuracy: 0.5328 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 11s 625ms/step - loss: 7.1935 - accuracy: 0.5165 - val_loss: 5.8827 - val_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 9s 532ms/step - loss: 5.2991 - accuracy: 0.5055 - val_loss: 4.5747 - val_accuracy: 0.5328 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 8s 472ms/step - loss: 4.2765 - accuracy: 0.5147 - val_loss: 3.8383 - val_accuracy: 0.5328 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 11s 634ms/step - loss: 3.6239 - accuracy: 0.4945 - val_loss: 3.3440 - val_accuracy: 0.5401 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 9s 556ms/step - loss: 3.2020 - accuracy: 0.5037 - val_loss: 3.0063 - val_accuracy: 0.5328 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 9s 513ms/step - loss: 2.9046 - accuracy: 0.5404 - val_loss: 2.7471 - val_accuracy: 0.6058 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 10s 564ms/step - loss: 2.6636 - accuracy: 0.5643 - val_loss: 2.5462 - val_accuracy: 0.6788 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 11s 627ms/step - loss: 2.4859 - accuracy: 0.5478 - val_loss: 2.4102 - val_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 12s 705ms/step - loss: 2.3337 - accuracy: 0.5496 - val_loss: 2.2622 - val_accuracy: 0.4891 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 9s 523ms/step - loss: 2.2055 - accuracy: 0.5496 - val_loss: 2.1432 - val_accuracy: 0.5328 - lr: 9.0484e-04\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 10s 600ms/step - loss: 2.1079 - accuracy: 0.5055 - val_loss: 2.0289 - val_accuracy: 0.7372 - lr: 8.1873e-04\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 10s 566ms/step - loss: 2.0075 - accuracy: 0.5772 - val_loss: 1.9466 - val_accuracy: 0.6934 - lr: 7.4082e-04\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 8s 476ms/step - loss: 1.9348 - accuracy: 0.5919 - val_loss: 1.8698 - val_accuracy: 0.7080 - lr: 6.7032e-04\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 11s 599ms/step - loss: 1.8641 - accuracy: 0.6048 - val_loss: 1.8080 - val_accuracy: 0.7007 - lr: 6.0653e-04\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 10s 580ms/step - loss: 1.8192 - accuracy: 0.5533 - val_loss: 1.7655 - val_accuracy: 0.6788 - lr: 5.4881e-04\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 9s 516ms/step - loss: 1.7673 - accuracy: 0.5974 - val_loss: 1.7145 - val_accuracy: 0.7153 - lr: 4.9659e-04\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 11s 642ms/step - loss: 1.7185 - accuracy: 0.6213 - val_loss: 1.6525 - val_accuracy: 0.7080 - lr: 4.4933e-04\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 9s 510ms/step - loss: 1.6961 - accuracy: 0.5827 - val_loss: 1.6710 - val_accuracy: 0.7153 - lr: 4.0657e-04\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 9s 521ms/step - loss: 1.6588 - accuracy: 0.5882 - val_loss: 1.5962 - val_accuracy: 0.6861 - lr: 3.6788e-04\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 11s 646ms/step - loss: 1.6141 - accuracy: 0.6324 - val_loss: 1.5767 - val_accuracy: 0.7299 - lr: 3.3287e-04\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 8s 476ms/step - loss: 1.6013 - accuracy: 0.6085 - val_loss: 1.5833 - val_accuracy: 0.6423 - lr: 3.0119e-04\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 10s 593ms/step - loss: 1.5850 - accuracy: 0.5974 - val_loss: 1.5375 - val_accuracy: 0.6715 - lr: 2.7253e-04\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 9s 559ms/step - loss: 1.5560 - accuracy: 0.6544 - val_loss: 1.5100 - val_accuracy: 0.6934 - lr: 2.4660e-04\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 8s 479ms/step - loss: 1.5338 - accuracy: 0.6268 - val_loss: 1.4895 - val_accuracy: 0.7226 - lr: 2.2313e-04\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 11s 611ms/step - loss: 1.5228 - accuracy: 0.6213 - val_loss: 1.4678 - val_accuracy: 0.7153 - lr: 2.0190e-04\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 13s 786ms/step - loss: 1.4889 - accuracy: 0.6581 - val_loss: 1.4435 - val_accuracy: 0.7080 - lr: 1.8268e-04\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 11s 630ms/step - loss: 1.4719 - accuracy: 0.6562 - val_loss: 1.4251 - val_accuracy: 0.7226 - lr: 1.6530e-04\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 9s 515ms/step - loss: 1.4589 - accuracy: 0.6728 - val_loss: 1.4230 - val_accuracy: 0.7226 - lr: 1.4957e-04\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 9s 490ms/step - loss: 1.4487 - accuracy: 0.6581 - val_loss: 1.4015 - val_accuracy: 0.7299 - lr: 1.3534e-04\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 11s 623ms/step - loss: 1.4308 - accuracy: 0.6452 - val_loss: 1.3887 - val_accuracy: 0.7299 - lr: 1.2246e-04\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 10s 585ms/step - loss: 1.4237 - accuracy: 0.6783 - val_loss: 1.3848 - val_accuracy: 0.7226 - lr: 1.1080e-04\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 9s 516ms/step - loss: 1.4003 - accuracy: 0.6673 - val_loss: 1.3695 - val_accuracy: 0.7518 - lr: 1.0026e-04\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 11s 610ms/step - loss: 1.4020 - accuracy: 0.6673 - val_loss: 1.3545 - val_accuracy: 0.7080 - lr: 9.0718e-05\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 11s 625ms/step - loss: 1.3878 - accuracy: 0.6857 - val_loss: 1.3443 - val_accuracy: 0.7153 - lr: 8.2085e-05\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 9s 503ms/step - loss: 1.3767 - accuracy: 0.7004 - val_loss: 1.3339 - val_accuracy: 0.7153 - lr: 7.4273e-05\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 10s 556ms/step - loss: 1.3969 - accuracy: 0.6544 - val_loss: 1.3465 - val_accuracy: 0.7518 - lr: 6.7205e-05\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 10s 606ms/step - loss: 1.3812 - accuracy: 0.6765 - val_loss: 1.3381 - val_accuracy: 0.7226 - lr: 6.0810e-05\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 10s 602ms/step - loss: 1.3726 - accuracy: 0.6618 - val_loss: 1.3241 - val_accuracy: 0.7226 - lr: 5.5023e-05\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 9s 497ms/step - loss: 1.3798 - accuracy: 0.6783 - val_loss: 1.3297 - val_accuracy: 0.7518 - lr: 4.9787e-05\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 10s 615ms/step - loss: 1.3532 - accuracy: 0.7096 - val_loss: 1.3118 - val_accuracy: 0.7226 - lr: 4.5049e-05\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 9s 532ms/step - loss: 1.3662 - accuracy: 0.6838 - val_loss: 1.3130 - val_accuracy: 0.7226 - lr: 4.0762e-05\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 8s 480ms/step - loss: 1.3592 - accuracy: 0.6673 - val_loss: 1.3107 - val_accuracy: 0.7299 - lr: 3.6883e-05\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 10s 573ms/step - loss: 1.3594 - accuracy: 0.6857 - val_loss: 1.3088 - val_accuracy: 0.7226 - lr: 3.3373e-05\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 11s 632ms/step - loss: 1.3574 - accuracy: 0.6857 - val_loss: 1.3044 - val_accuracy: 0.7299 - lr: 3.0197e-05\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 10s 545ms/step - loss: 1.3553 - accuracy: 0.6673 - val_loss: 1.3083 - val_accuracy: 0.7226 - lr: 2.7324e-05\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 11s 623ms/step - loss: 1.3518 - accuracy: 0.6949 - val_loss: 1.3004 - val_accuracy: 0.7226 - lr: 2.4723e-05\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 9s 520ms/step - loss: 1.3502 - accuracy: 0.6673 - val_loss: 1.2934 - val_accuracy: 0.7299 - lr: 2.2371e-05\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 9s 517ms/step - loss: 1.3363 - accuracy: 0.6765 - val_loss: 1.2914 - val_accuracy: 0.7226 - lr: 2.0242e-05\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 11s 624ms/step - loss: 1.3317 - accuracy: 0.6912 - val_loss: 1.2908 - val_accuracy: 0.7372 - lr: 1.8316e-05\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 1.2908 - accuracy: 0.7372\n",
            "Validation Loss for Fold 1: 1.2907966375350952\n",
            "Validation Accuracy for Fold 1: 0.7372262477874756\n",
            "5/5 [==============================] - 1s 147ms/step\n",
            "Classification Report for Fold 1 :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       child       0.77      0.73      0.75        73\n",
            "       adult       0.71      0.75      0.73        64\n",
            "\n",
            "    accuracy                           0.74       137\n",
            "   macro avg       0.74      0.74      0.74       137\n",
            "weighted avg       0.74      0.74      0.74       137\n",
            "\n",
            "Confusion Matrix for Fold 1 :\n",
            " [[53 20]\n",
            " [16 48]]\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 16s 695ms/step - loss: 11.4224 - accuracy: 0.5229 - val_loss: 7.8865 - val_accuracy: 0.4706 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 11s 620ms/step - loss: 7.1734 - accuracy: 0.5505 - val_loss: 5.8506 - val_accuracy: 0.5294 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 10s 612ms/step - loss: 5.3643 - accuracy: 0.5174 - val_loss: 4.6123 - val_accuracy: 0.4706 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 9s 506ms/step - loss: 4.3552 - accuracy: 0.5138 - val_loss: 3.8712 - val_accuracy: 0.5441 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 10s 518ms/step - loss: 3.7208 - accuracy: 0.5358 - val_loss: 3.4617 - val_accuracy: 0.4706 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 11s 590ms/step - loss: 3.3164 - accuracy: 0.4991 - val_loss: 3.1113 - val_accuracy: 0.5221 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 11s 610ms/step - loss: 3.0314 - accuracy: 0.4991 - val_loss: 2.8772 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 10s 516ms/step - loss: 2.8188 - accuracy: 0.4991 - val_loss: 2.6677 - val_accuracy: 0.6618 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 11s 619ms/step - loss: 2.6085 - accuracy: 0.5413 - val_loss: 2.5001 - val_accuracy: 0.6691 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 10s 519ms/step - loss: 2.4774 - accuracy: 0.5468 - val_loss: 2.3853 - val_accuracy: 0.5294 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 13s 724ms/step - loss: 2.3355 - accuracy: 0.5156 - val_loss: 2.2677 - val_accuracy: 0.6618 - lr: 9.0484e-04\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 11s 598ms/step - loss: 2.2307 - accuracy: 0.5101 - val_loss: 2.1683 - val_accuracy: 0.6618 - lr: 8.1873e-04\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 9s 516ms/step - loss: 2.1378 - accuracy: 0.5394 - val_loss: 2.0877 - val_accuracy: 0.6912 - lr: 7.4082e-04\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 10s 532ms/step - loss: 2.0688 - accuracy: 0.4991 - val_loss: 2.0294 - val_accuracy: 0.5294 - lr: 6.7032e-04\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 10s 579ms/step - loss: 2.0014 - accuracy: 0.4917 - val_loss: 1.9713 - val_accuracy: 0.5294 - lr: 6.0653e-04\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 9s 477ms/step - loss: 1.9486 - accuracy: 0.5211 - val_loss: 1.9210 - val_accuracy: 0.5294 - lr: 5.4881e-04\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 10s 582ms/step - loss: 1.9097 - accuracy: 0.5009 - val_loss: 1.8758 - val_accuracy: 0.5294 - lr: 4.9659e-04\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 10s 551ms/step - loss: 1.8664 - accuracy: 0.5376 - val_loss: 1.8405 - val_accuracy: 0.6397 - lr: 4.4933e-04\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 9s 478ms/step - loss: 1.8250 - accuracy: 0.5596 - val_loss: 1.8022 - val_accuracy: 0.6471 - lr: 4.0657e-04\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 11s 632ms/step - loss: 1.7891 - accuracy: 0.5725 - val_loss: 1.7669 - val_accuracy: 0.6029 - lr: 3.6788e-04\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 9s 487ms/step - loss: 1.7597 - accuracy: 0.5670 - val_loss: 1.7382 - val_accuracy: 0.6029 - lr: 3.3287e-04\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 10s 514ms/step - loss: 1.7306 - accuracy: 0.5523 - val_loss: 1.7115 - val_accuracy: 0.5294 - lr: 3.0119e-04\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 10s 580ms/step - loss: 1.7169 - accuracy: 0.5321 - val_loss: 1.6979 - val_accuracy: 0.6250 - lr: 2.7253e-04\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 10s 566ms/step - loss: 1.6920 - accuracy: 0.5615 - val_loss: 1.6702 - val_accuracy: 0.6765 - lr: 2.4660e-04\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 8s 459ms/step - loss: 1.6655 - accuracy: 0.5872 - val_loss: 1.6491 - val_accuracy: 0.5441 - lr: 2.2313e-04\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 11s 597ms/step - loss: 1.6601 - accuracy: 0.5358 - val_loss: 1.6441 - val_accuracy: 0.6250 - lr: 2.0190e-04\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 10s 562ms/step - loss: 1.6374 - accuracy: 0.5817 - val_loss: 1.6175 - val_accuracy: 0.6544 - lr: 1.8268e-04\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 8s 459ms/step - loss: 1.6225 - accuracy: 0.5872 - val_loss: 1.6062 - val_accuracy: 0.7059 - lr: 1.6530e-04\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 10s 571ms/step - loss: 1.6132 - accuracy: 0.6092 - val_loss: 1.6084 - val_accuracy: 0.6397 - lr: 1.4957e-04\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 11s 590ms/step - loss: 1.5973 - accuracy: 0.6128 - val_loss: 1.5822 - val_accuracy: 0.6838 - lr: 1.3534e-04\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 11s 604ms/step - loss: 1.5887 - accuracy: 0.6092 - val_loss: 1.5768 - val_accuracy: 0.6985 - lr: 1.2246e-04\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 10s 543ms/step - loss: 1.5700 - accuracy: 0.6073 - val_loss: 1.5687 - val_accuracy: 0.6838 - lr: 1.1080e-04\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 9s 491ms/step - loss: 1.5653 - accuracy: 0.6275 - val_loss: 1.5563 - val_accuracy: 0.6985 - lr: 1.0026e-04\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 10s 586ms/step - loss: 1.5677 - accuracy: 0.6037 - val_loss: 1.5518 - val_accuracy: 0.6985 - lr: 9.0718e-05\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 9s 468ms/step - loss: 1.5637 - accuracy: 0.5450 - val_loss: 1.5411 - val_accuracy: 0.6985 - lr: 8.2085e-05\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 10s 557ms/step - loss: 1.5475 - accuracy: 0.5872 - val_loss: 1.5359 - val_accuracy: 0.6912 - lr: 7.4273e-05\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 11s 593ms/step - loss: 1.5412 - accuracy: 0.5945 - val_loss: 1.5296 - val_accuracy: 0.6912 - lr: 6.7205e-05\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 10s 517ms/step - loss: 1.5383 - accuracy: 0.5817 - val_loss: 1.5230 - val_accuracy: 0.7059 - lr: 6.0810e-05\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 10s 583ms/step - loss: 1.5325 - accuracy: 0.5963 - val_loss: 1.5180 - val_accuracy: 0.6985 - lr: 5.5023e-05\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 10s 583ms/step - loss: 1.5241 - accuracy: 0.6202 - val_loss: 1.5134 - val_accuracy: 0.7059 - lr: 4.9787e-05\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 10s 530ms/step - loss: 1.5183 - accuracy: 0.6165 - val_loss: 1.5068 - val_accuracy: 0.6618 - lr: 4.5049e-05\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 10s 578ms/step - loss: 1.5198 - accuracy: 0.5872 - val_loss: 1.5028 - val_accuracy: 0.6691 - lr: 4.0762e-05\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 8s 460ms/step - loss: 1.5104 - accuracy: 0.6128 - val_loss: 1.5016 - val_accuracy: 0.7132 - lr: 3.6883e-05\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 11s 573ms/step - loss: 1.5063 - accuracy: 0.6349 - val_loss: 1.4988 - val_accuracy: 0.7059 - lr: 3.3373e-05\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 10s 530ms/step - loss: 1.5075 - accuracy: 0.6165 - val_loss: 1.4963 - val_accuracy: 0.7132 - lr: 3.0197e-05\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 10s 601ms/step - loss: 1.5098 - accuracy: 0.5780 - val_loss: 1.4940 - val_accuracy: 0.7132 - lr: 2.7324e-05\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 11s 600ms/step - loss: 1.4939 - accuracy: 0.6440 - val_loss: 1.4923 - val_accuracy: 0.7059 - lr: 2.4723e-05\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 9s 478ms/step - loss: 1.5030 - accuracy: 0.6073 - val_loss: 1.4947 - val_accuracy: 0.6912 - lr: 2.2371e-05\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 10s 533ms/step - loss: 1.4994 - accuracy: 0.6385 - val_loss: 1.4898 - val_accuracy: 0.6912 - lr: 2.0242e-05\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 10s 569ms/step - loss: 1.4968 - accuracy: 0.6257 - val_loss: 1.4859 - val_accuracy: 0.7132 - lr: 1.8316e-05\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 1.4859 - accuracy: 0.7132\n",
            "Validation Loss for Fold 2: 1.485854983329773\n",
            "Validation Accuracy for Fold 2: 0.7132353186607361\n",
            "5/5 [==============================] - 1s 146ms/step\n",
            "Classification Report for Fold 2 :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       child       0.75      0.59      0.66        64\n",
            "       adult       0.69      0.82      0.75        72\n",
            "\n",
            "    accuracy                           0.71       136\n",
            "   macro avg       0.72      0.71      0.71       136\n",
            "weighted avg       0.72      0.71      0.71       136\n",
            "\n",
            "Confusion Matrix for Fold 2 :\n",
            " [[38 26]\n",
            " [13 59]]\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 12s 578ms/step - loss: 11.5403 - accuracy: 0.5211 - val_loss: 7.9979 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 8s 489ms/step - loss: 7.6028 - accuracy: 0.4844 - val_loss: 5.7793 - val_accuracy: 0.5221 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 11s 605ms/step - loss: 5.3973 - accuracy: 0.5248 - val_loss: 4.6708 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 9s 522ms/step - loss: 4.4627 - accuracy: 0.4881 - val_loss: 3.9796 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 9s 492ms/step - loss: 3.8220 - accuracy: 0.5211 - val_loss: 3.5440 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 10s 537ms/step - loss: 3.4283 - accuracy: 0.5046 - val_loss: 3.2360 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 10s 598ms/step - loss: 3.1550 - accuracy: 0.5046 - val_loss: 3.0021 - val_accuracy: 0.5882 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 9s 504ms/step - loss: 2.9301 - accuracy: 0.4991 - val_loss: 2.8025 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 8s 453ms/step - loss: 2.7289 - accuracy: 0.5229 - val_loss: 2.6414 - val_accuracy: 0.5294 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 11s 597ms/step - loss: 2.5696 - accuracy: 0.5688 - val_loss: 2.5043 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 9s 492ms/step - loss: 2.4552 - accuracy: 0.5266 - val_loss: 2.3815 - val_accuracy: 0.4926 - lr: 9.0484e-04\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 9s 471ms/step - loss: 2.3354 - accuracy: 0.5413 - val_loss: 2.2842 - val_accuracy: 0.4926 - lr: 8.1873e-04\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 13s 709ms/step - loss: 2.2468 - accuracy: 0.5284 - val_loss: 2.1997 - val_accuracy: 0.6471 - lr: 7.4082e-04\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 10s 537ms/step - loss: 2.1738 - accuracy: 0.5523 - val_loss: 2.1365 - val_accuracy: 0.5074 - lr: 6.7032e-04\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 9s 486ms/step - loss: 2.1130 - accuracy: 0.5174 - val_loss: 2.0791 - val_accuracy: 0.5000 - lr: 6.0653e-04\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 11s 572ms/step - loss: 2.0632 - accuracy: 0.5193 - val_loss: 2.0301 - val_accuracy: 0.5221 - lr: 5.4881e-04\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 10s 535ms/step - loss: 2.0220 - accuracy: 0.4954 - val_loss: 1.9855 - val_accuracy: 0.5368 - lr: 4.9659e-04\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 9s 492ms/step - loss: 1.9621 - accuracy: 0.5725 - val_loss: 1.9412 - val_accuracy: 0.5809 - lr: 4.4933e-04\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 10s 515ms/step - loss: 1.9261 - accuracy: 0.5890 - val_loss: 1.9025 - val_accuracy: 0.6765 - lr: 4.0657e-04\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 1.8968 - accuracy: 0.5523 - val_loss: 1.8815 - val_accuracy: 0.5294 - lr: 3.6788e-04\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 9s 487ms/step - loss: 1.8642 - accuracy: 0.5872 - val_loss: 1.8397 - val_accuracy: 0.6324 - lr: 3.3287e-04\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 11s 601ms/step - loss: 1.8498 - accuracy: 0.5743 - val_loss: 1.8238 - val_accuracy: 0.6618 - lr: 3.0119e-04\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 8s 450ms/step - loss: 1.8150 - accuracy: 0.5890 - val_loss: 1.7897 - val_accuracy: 0.6397 - lr: 2.7253e-04\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 11s 594ms/step - loss: 1.8031 - accuracy: 0.5706 - val_loss: 1.7647 - val_accuracy: 0.6838 - lr: 2.4660e-04\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 10s 533ms/step - loss: 1.7740 - accuracy: 0.5798 - val_loss: 1.7631 - val_accuracy: 0.6250 - lr: 2.2313e-04\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 9s 465ms/step - loss: 1.7581 - accuracy: 0.5798 - val_loss: 1.7291 - val_accuracy: 0.6397 - lr: 2.0190e-04\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 11s 613ms/step - loss: 1.7306 - accuracy: 0.6385 - val_loss: 1.7112 - val_accuracy: 0.6471 - lr: 1.8268e-04\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 9s 490ms/step - loss: 1.7152 - accuracy: 0.6037 - val_loss: 1.7043 - val_accuracy: 0.6912 - lr: 1.6530e-04\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 12s 631ms/step - loss: 1.7108 - accuracy: 0.6275 - val_loss: 1.6904 - val_accuracy: 0.6544 - lr: 1.4957e-04\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 10s 570ms/step - loss: 1.6849 - accuracy: 0.6495 - val_loss: 1.6637 - val_accuracy: 0.7279 - lr: 1.3534e-04\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 8s 454ms/step - loss: 1.6870 - accuracy: 0.6220 - val_loss: 1.6570 - val_accuracy: 0.7206 - lr: 1.2246e-04\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 10s 544ms/step - loss: 1.6836 - accuracy: 0.6073 - val_loss: 1.6515 - val_accuracy: 0.7279 - lr: 1.1080e-04\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 10s 559ms/step - loss: 1.6480 - accuracy: 0.6440 - val_loss: 1.6360 - val_accuracy: 0.7132 - lr: 1.0026e-04\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 8s 450ms/step - loss: 1.6553 - accuracy: 0.6312 - val_loss: 1.6419 - val_accuracy: 0.6324 - lr: 9.0718e-05\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 10s 570ms/step - loss: 1.6436 - accuracy: 0.6275 - val_loss: 1.6176 - val_accuracy: 0.7206 - lr: 8.2085e-05\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 10s 604ms/step - loss: 1.6563 - accuracy: 0.6110 - val_loss: 1.6020 - val_accuracy: 0.7500 - lr: 7.4273e-05\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 9s 525ms/step - loss: 1.6303 - accuracy: 0.6532 - val_loss: 1.6079 - val_accuracy: 0.7206 - lr: 6.7205e-05\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 10s 572ms/step - loss: 1.6288 - accuracy: 0.6422 - val_loss: 1.5989 - val_accuracy: 0.7206 - lr: 6.0810e-05\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 10s 533ms/step - loss: 1.6147 - accuracy: 0.6220 - val_loss: 1.5879 - val_accuracy: 0.7426 - lr: 5.5023e-05\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 9s 455ms/step - loss: 1.6167 - accuracy: 0.6569 - val_loss: 1.5849 - val_accuracy: 0.7206 - lr: 4.9787e-05\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 11s 611ms/step - loss: 1.5950 - accuracy: 0.6881 - val_loss: 1.5845 - val_accuracy: 0.7132 - lr: 4.5049e-05\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 11s 597ms/step - loss: 1.6014 - accuracy: 0.6514 - val_loss: 1.5716 - val_accuracy: 0.7353 - lr: 4.0762e-05\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 8s 445ms/step - loss: 1.5957 - accuracy: 0.6367 - val_loss: 1.5731 - val_accuracy: 0.7132 - lr: 3.6883e-05\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 9s 460ms/step - loss: 1.5921 - accuracy: 0.6367 - val_loss: 1.5718 - val_accuracy: 0.7132 - lr: 3.3373e-05\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 10s 560ms/step - loss: 1.6051 - accuracy: 0.6312 - val_loss: 1.5723 - val_accuracy: 0.7426 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 9s 502ms/step - loss: 1.5826 - accuracy: 0.6826 - val_loss: 1.5724 - val_accuracy: 0.7426 - lr: 9.0484e-06\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 9s 518ms/step - loss: 1.5916 - accuracy: 0.6789 - val_loss: 1.5741 - val_accuracy: 0.7206 - lr: 8.1873e-06\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 1.5716 - accuracy: 0.7353\n",
            "Validation Loss for Fold 3: 1.5715912580490112\n",
            "Validation Accuracy for Fold 3: 0.7352941036224365\n",
            "5/5 [==============================] - 1s 149ms/step\n",
            "Classification Report for Fold 3 :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       child       0.71      0.78      0.74        67\n",
            "       adult       0.76      0.70      0.73        69\n",
            "\n",
            "    accuracy                           0.74       136\n",
            "   macro avg       0.74      0.74      0.74       136\n",
            "weighted avg       0.74      0.74      0.73       136\n",
            "\n",
            "Confusion Matrix for Fold 3 :\n",
            " [[52 15]\n",
            " [21 48]]\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 12s 587ms/step - loss: 11.5596 - accuracy: 0.5119 - val_loss: 8.0423 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 11s 602ms/step - loss: 7.3176 - accuracy: 0.4734 - val_loss: 5.7865 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 8s 454ms/step - loss: 5.4951 - accuracy: 0.4972 - val_loss: 4.7422 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 9s 455ms/step - loss: 4.4092 - accuracy: 0.5266 - val_loss: 3.9809 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 3.8174 - accuracy: 0.5284 - val_loss: 3.5077 - val_accuracy: 0.6912 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 9s 488ms/step - loss: 3.4049 - accuracy: 0.5303 - val_loss: 3.2271 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 9s 503ms/step - loss: 3.1464 - accuracy: 0.5358 - val_loss: 2.9600 - val_accuracy: 0.5735 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 11s 605ms/step - loss: 2.9178 - accuracy: 0.5339 - val_loss: 2.7814 - val_accuracy: 0.6544 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 9s 524ms/step - loss: 2.7444 - accuracy: 0.4936 - val_loss: 2.6347 - val_accuracy: 0.5147 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 8s 453ms/step - loss: 2.5760 - accuracy: 0.5303 - val_loss: 2.4910 - val_accuracy: 0.5368 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 11s 615ms/step - loss: 2.4302 - accuracy: 0.5248 - val_loss: 2.3586 - val_accuracy: 0.6985 - lr: 9.0484e-04\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 10s 572ms/step - loss: 2.3360 - accuracy: 0.5376 - val_loss: 2.2831 - val_accuracy: 0.5000 - lr: 8.1873e-04\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 10s 512ms/step - loss: 2.2728 - accuracy: 0.4844 - val_loss: 2.2075 - val_accuracy: 0.5000 - lr: 7.4082e-04\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 10s 579ms/step - loss: 2.1789 - accuracy: 0.5083 - val_loss: 2.1391 - val_accuracy: 0.5000 - lr: 6.7032e-04\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 9s 504ms/step - loss: 2.1110 - accuracy: 0.5009 - val_loss: 2.0754 - val_accuracy: 0.5000 - lr: 6.0653e-04\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 9s 502ms/step - loss: 2.0520 - accuracy: 0.5028 - val_loss: 2.0223 - val_accuracy: 0.5000 - lr: 5.4881e-04\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 10s 562ms/step - loss: 2.0020 - accuracy: 0.5303 - val_loss: 1.9754 - val_accuracy: 0.7059 - lr: 4.9659e-04\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 10s 527ms/step - loss: 1.9680 - accuracy: 0.5211 - val_loss: 1.9403 - val_accuracy: 0.5000 - lr: 4.4933e-04\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 10s 581ms/step - loss: 1.9243 - accuracy: 0.5229 - val_loss: 1.9078 - val_accuracy: 0.5000 - lr: 4.0657e-04\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 10s 559ms/step - loss: 1.8945 - accuracy: 0.4991 - val_loss: 1.8774 - val_accuracy: 0.5000 - lr: 3.6788e-04\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 10s 533ms/step - loss: 1.8664 - accuracy: 0.4972 - val_loss: 1.8495 - val_accuracy: 0.5000 - lr: 3.3287e-04\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 8s 454ms/step - loss: 1.8398 - accuracy: 0.4899 - val_loss: 1.8238 - val_accuracy: 0.5000 - lr: 3.0119e-04\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 11s 609ms/step - loss: 1.8183 - accuracy: 0.4991 - val_loss: 1.8017 - val_accuracy: 0.5000 - lr: 2.7253e-04\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 8s 451ms/step - loss: 1.8012 - accuracy: 0.5083 - val_loss: 1.7901 - val_accuracy: 0.5000 - lr: 2.4660e-04\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 10s 555ms/step - loss: 1.7817 - accuracy: 0.4624 - val_loss: 1.7726 - val_accuracy: 0.5368 - lr: 2.2313e-04\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 10s 567ms/step - loss: 1.7650 - accuracy: 0.4972 - val_loss: 1.7562 - val_accuracy: 0.5000 - lr: 2.0190e-04\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 9s 489ms/step - loss: 1.7501 - accuracy: 0.5028 - val_loss: 1.7422 - val_accuracy: 0.5368 - lr: 1.8268e-04\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 11s 634ms/step - loss: 1.7359 - accuracy: 0.5156 - val_loss: 1.7297 - val_accuracy: 0.5000 - lr: 1.6530e-04\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 11s 597ms/step - loss: 1.7242 - accuracy: 0.5046 - val_loss: 1.7180 - val_accuracy: 0.5000 - lr: 1.4957e-04\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 8s 481ms/step - loss: 1.7124 - accuracy: 0.5303 - val_loss: 1.7073 - val_accuracy: 0.5147 - lr: 1.3534e-04\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 10s 560ms/step - loss: 1.7002 - accuracy: 0.5560 - val_loss: 1.6936 - val_accuracy: 0.6250 - lr: 1.2246e-04\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 10s 561ms/step - loss: 1.6913 - accuracy: 0.4991 - val_loss: 1.6839 - val_accuracy: 0.5882 - lr: 1.1080e-04\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 9s 486ms/step - loss: 1.6807 - accuracy: 0.5560 - val_loss: 1.6748 - val_accuracy: 0.5809 - lr: 1.0026e-04\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 11s 593ms/step - loss: 1.6746 - accuracy: 0.5101 - val_loss: 1.6674 - val_accuracy: 0.5074 - lr: 9.0718e-05\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 11s 613ms/step - loss: 1.6652 - accuracy: 0.5761 - val_loss: 1.6590 - val_accuracy: 0.5000 - lr: 8.2085e-05\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 9s 486ms/step - loss: 1.6617 - accuracy: 0.4972 - val_loss: 1.6532 - val_accuracy: 0.5000 - lr: 7.4273e-05\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 8s 456ms/step - loss: 1.6557 - accuracy: 0.5046 - val_loss: 1.6462 - val_accuracy: 0.6250 - lr: 6.7205e-05\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 10s 579ms/step - loss: 1.6458 - accuracy: 0.5523 - val_loss: 1.6395 - val_accuracy: 0.6029 - lr: 6.0810e-05\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 10s 529ms/step - loss: 1.6459 - accuracy: 0.5193 - val_loss: 1.6365 - val_accuracy: 0.7132 - lr: 5.5023e-05\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 11s 582ms/step - loss: 1.6406 - accuracy: 0.5688 - val_loss: 1.6338 - val_accuracy: 0.7868 - lr: 4.9787e-05\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 11s 646ms/step - loss: 1.6341 - accuracy: 0.6110 - val_loss: 1.6272 - val_accuracy: 0.6838 - lr: 4.5049e-05\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 9s 489ms/step - loss: 1.6319 - accuracy: 0.5138 - val_loss: 1.6224 - val_accuracy: 0.6618 - lr: 4.0762e-05\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 10s 542ms/step - loss: 1.6302 - accuracy: 0.5358 - val_loss: 1.6231 - val_accuracy: 0.8162 - lr: 3.6883e-05\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 10s 577ms/step - loss: 1.6250 - accuracy: 0.5376 - val_loss: 1.6181 - val_accuracy: 0.7941 - lr: 3.3373e-05\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 10s 519ms/step - loss: 1.6216 - accuracy: 0.5450 - val_loss: 1.6126 - val_accuracy: 0.7206 - lr: 3.0197e-05\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 10s 571ms/step - loss: 1.6144 - accuracy: 0.6018 - val_loss: 1.6112 - val_accuracy: 0.7647 - lr: 2.7324e-05\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 10s 534ms/step - loss: 1.6166 - accuracy: 0.5523 - val_loss: 1.6090 - val_accuracy: 0.7647 - lr: 2.4723e-05\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 9s 496ms/step - loss: 1.6116 - accuracy: 0.5688 - val_loss: 1.6051 - val_accuracy: 0.7279 - lr: 2.2371e-05\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 10s 566ms/step - loss: 1.6125 - accuracy: 0.5505 - val_loss: 1.6038 - val_accuracy: 0.7647 - lr: 2.0242e-05\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 10s 541ms/step - loss: 1.6095 - accuracy: 0.5908 - val_loss: 1.6011 - val_accuracy: 0.7426 - lr: 1.8316e-05\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 1.6011 - accuracy: 0.7426\n",
            "Validation Loss for Fold 4: 1.6011173725128174\n",
            "Validation Accuracy for Fold 4: 0.7426470518112183\n",
            "5/5 [==============================] - 1s 146ms/step\n",
            "Classification Report for Fold 4 :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       child       0.95      0.51      0.67        68\n",
            "       adult       0.67      0.97      0.79        68\n",
            "\n",
            "    accuracy                           0.74       136\n",
            "   macro avg       0.81      0.74      0.73       136\n",
            "weighted avg       0.81      0.74      0.73       136\n",
            "\n",
            "Confusion Matrix for Fold 4 :\n",
            " [[35 33]\n",
            " [ 2 66]]\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 13s 614ms/step - loss: 12.0856 - accuracy: 0.5211 - val_loss: 8.0741 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 9s 494ms/step - loss: 7.5873 - accuracy: 0.5101 - val_loss: 6.1375 - val_accuracy: 0.5294 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 9s 497ms/step - loss: 5.7038 - accuracy: 0.5064 - val_loss: 5.0122 - val_accuracy: 0.4926 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 4.7161 - accuracy: 0.4972 - val_loss: 4.2614 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 10s 561ms/step - loss: 4.0611 - accuracy: 0.5560 - val_loss: 3.8266 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 8s 462ms/step - loss: 3.6766 - accuracy: 0.5156 - val_loss: 3.4745 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 10s 556ms/step - loss: 3.3820 - accuracy: 0.5413 - val_loss: 3.2174 - val_accuracy: 0.5147 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 12s 675ms/step - loss: 3.1369 - accuracy: 0.5266 - val_loss: 3.0080 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 9s 515ms/step - loss: 2.9480 - accuracy: 0.4972 - val_loss: 2.8426 - val_accuracy: 0.5074 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 10s 522ms/step - loss: 2.7709 - accuracy: 0.4752 - val_loss: 2.6738 - val_accuracy: 0.7206 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 11s 605ms/step - loss: 2.6194 - accuracy: 0.5339 - val_loss: 2.5469 - val_accuracy: 0.5882 - lr: 9.0484e-04\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 9s 497ms/step - loss: 2.5034 - accuracy: 0.5688 - val_loss: 2.4643 - val_accuracy: 0.4926 - lr: 8.1873e-04\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 9s 490ms/step - loss: 2.4165 - accuracy: 0.5266 - val_loss: 2.3528 - val_accuracy: 0.6103 - lr: 7.4082e-04\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 10s 583ms/step - loss: 2.3366 - accuracy: 0.5046 - val_loss: 2.2858 - val_accuracy: 0.4926 - lr: 6.7032e-04\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 9s 495ms/step - loss: 2.2654 - accuracy: 0.5450 - val_loss: 2.1998 - val_accuracy: 0.6912 - lr: 6.0653e-04\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 10s 505ms/step - loss: 2.2118 - accuracy: 0.4972 - val_loss: 2.1654 - val_accuracy: 0.6029 - lr: 5.4881e-04\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 10s 571ms/step - loss: 2.1429 - accuracy: 0.5413 - val_loss: 2.1101 - val_accuracy: 0.6029 - lr: 4.9659e-04\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 9s 503ms/step - loss: 2.1013 - accuracy: 0.5431 - val_loss: 2.0692 - val_accuracy: 0.7647 - lr: 4.4933e-04\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 9s 505ms/step - loss: 2.0637 - accuracy: 0.5523 - val_loss: 2.0227 - val_accuracy: 0.5000 - lr: 4.0657e-04\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 10s 560ms/step - loss: 2.0389 - accuracy: 0.5174 - val_loss: 2.0244 - val_accuracy: 0.5074 - lr: 3.6788e-04\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 9s 510ms/step - loss: 2.0130 - accuracy: 0.4954 - val_loss: 1.9957 - val_accuracy: 0.5074 - lr: 3.3287e-04\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 9s 491ms/step - loss: 1.9835 - accuracy: 0.5174 - val_loss: 1.9672 - val_accuracy: 0.5074 - lr: 3.0119e-04\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 11s 624ms/step - loss: 1.9582 - accuracy: 0.4679 - val_loss: 1.9425 - val_accuracy: 0.5074 - lr: 2.7253e-04\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 10s 563ms/step - loss: 1.9316 - accuracy: 0.5101 - val_loss: 1.9209 - val_accuracy: 0.5000 - lr: 2.4660e-04\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 8s 463ms/step - loss: 1.9127 - accuracy: 0.5009 - val_loss: 1.9006 - val_accuracy: 0.5294 - lr: 2.2313e-04\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 1.8906 - accuracy: 0.5064 - val_loss: 1.8822 - val_accuracy: 0.5441 - lr: 2.0190e-04\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 9s 499ms/step - loss: 1.8759 - accuracy: 0.5229 - val_loss: 1.8700 - val_accuracy: 0.4926 - lr: 1.8268e-04\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 8s 455ms/step - loss: 1.8641 - accuracy: 0.5284 - val_loss: 1.8511 - val_accuracy: 0.5221 - lr: 1.6530e-04\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 12s 692ms/step - loss: 1.8467 - accuracy: 0.5284 - val_loss: 1.8395 - val_accuracy: 0.5441 - lr: 1.4957e-04\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 10s 528ms/step - loss: 1.8336 - accuracy: 0.5174 - val_loss: 1.8259 - val_accuracy: 0.5074 - lr: 1.3534e-04\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 9s 520ms/step - loss: 1.8244 - accuracy: 0.5339 - val_loss: 1.8113 - val_accuracy: 0.6691 - lr: 1.2246e-04\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 10s 557ms/step - loss: 1.8114 - accuracy: 0.5450 - val_loss: 1.8014 - val_accuracy: 0.6618 - lr: 1.1080e-04\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 11s 608ms/step - loss: 1.8006 - accuracy: 0.5339 - val_loss: 1.7930 - val_accuracy: 0.6691 - lr: 1.0026e-04\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 9s 491ms/step - loss: 1.7897 - accuracy: 0.5505 - val_loss: 1.7801 - val_accuracy: 0.6912 - lr: 9.0718e-05\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 9s 490ms/step - loss: 1.7835 - accuracy: 0.5303 - val_loss: 1.7726 - val_accuracy: 0.6397 - lr: 8.2085e-05\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 11s 571ms/step - loss: 1.7749 - accuracy: 0.5394 - val_loss: 1.7644 - val_accuracy: 0.6985 - lr: 7.4273e-05\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 11s 616ms/step - loss: 1.7620 - accuracy: 0.5945 - val_loss: 1.7558 - val_accuracy: 0.7206 - lr: 6.7205e-05\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 8s 455ms/step - loss: 1.7589 - accuracy: 0.5615 - val_loss: 1.7493 - val_accuracy: 0.7206 - lr: 6.0810e-05\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 10s 536ms/step - loss: 1.7500 - accuracy: 0.5688 - val_loss: 1.7429 - val_accuracy: 0.6838 - lr: 5.5023e-05\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 1.7398 - accuracy: 0.6037 - val_loss: 1.7390 - val_accuracy: 0.5735 - lr: 4.9787e-05\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 9s 492ms/step - loss: 1.7431 - accuracy: 0.5358 - val_loss: 1.7292 - val_accuracy: 0.7426 - lr: 4.5049e-05\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 11s 587ms/step - loss: 1.7427 - accuracy: 0.5486 - val_loss: 1.7260 - val_accuracy: 0.7206 - lr: 4.0762e-05\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 10s 568ms/step - loss: 1.7275 - accuracy: 0.5982 - val_loss: 1.7225 - val_accuracy: 0.7059 - lr: 3.6883e-05\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 8s 457ms/step - loss: 1.7262 - accuracy: 0.5633 - val_loss: 1.7157 - val_accuracy: 0.7206 - lr: 3.3373e-05\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 11s 602ms/step - loss: 1.7251 - accuracy: 0.5670 - val_loss: 1.7114 - val_accuracy: 0.7059 - lr: 3.0197e-05\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 10s 568ms/step - loss: 1.7267 - accuracy: 0.5670 - val_loss: 1.7071 - val_accuracy: 0.7132 - lr: 2.7324e-05\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 8s 462ms/step - loss: 1.7152 - accuracy: 0.5780 - val_loss: 1.7040 - val_accuracy: 0.7279 - lr: 2.4723e-05\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 11s 593ms/step - loss: 1.7114 - accuracy: 0.6037 - val_loss: 1.7023 - val_accuracy: 0.7279 - lr: 2.2371e-05\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 10s 577ms/step - loss: 1.7206 - accuracy: 0.5358 - val_loss: 1.6999 - val_accuracy: 0.7279 - lr: 2.0242e-05\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 8s 461ms/step - loss: 1.7183 - accuracy: 0.5394 - val_loss: 1.6976 - val_accuracy: 0.7132 - lr: 1.8316e-05\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 1.6976 - accuracy: 0.7132\n",
            "Validation Loss for Fold 5: 1.6975629329681396\n",
            "Validation Accuracy for Fold 5: 0.7132353186607361\n",
            "5/5 [==============================] - 1s 149ms/step\n",
            "Classification Report for Fold 5 :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       child       0.71      0.72      0.72        69\n",
            "       adult       0.71      0.70      0.71        67\n",
            "\n",
            "    accuracy                           0.71       136\n",
            "   macro avg       0.71      0.71      0.71       136\n",
            "weighted avg       0.71      0.71      0.71       136\n",
            "\n",
            "Confusion Matrix for Fold 5 :\n",
            " [[50 19]\n",
            " [20 47]]\n",
            "Average Validation Loss: 1.5293846368789672\n",
            "Average Validation Accuracy: 0.7283276081085205\n",
            "Figure(1200x600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OnBoardCounter\n",
        "!python Detection_Counting.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKfe1g3BMfEy",
        "outputId": "8dd9cdc2-8040-4540-ff8c-a1193761ec1a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'OnBoardCounter'\n",
            "/content/OnBoardCounter\n",
            "2024-05-31 05:52:29.451231: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-31 05:52:29.451295: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-31 05:52:29.453246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-31 05:52:29.464537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-31 05:52:31.093995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.26-py3-none-any.whl (779 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.4/779.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.26\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'pillow>=10.3.0', 'requests>=2.32.0'] not found, attempting AutoUpdate...\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 7.1 MB/s eta 0:00:00\n",
            "Collecting pillow>=10.3.0\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 130.6 MB/s eta 0:00:00\n",
            "Collecting requests>=2.32.0\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 284.2 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 272.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, requests, pillow, gitdb, gitpython\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pillow-10.3.0 requests-2.32.3 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.6s, installed 3 packages: ['gitpython>=3.1.30', 'pillow>=10.3.0', 'requests>=2.32.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2024-5-31 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "2024-05-31 05:53:55.000196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.006799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.007057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.007860: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.008536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.008895: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.009503: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.009907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.010222: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-05-31 05:53:55.010380: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-31 05:53:55.010677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13765 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "[ WARN:0@90.610] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
            "[ERROR:0@90.610] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  from filterpy.kalman import KalmanFilter\n",
        "# ModuleNotFoundError: No module named 'filterpy' give me a code to have thse modules\n",
        "\n",
        "!pip install filterpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ttqWFPNDgI",
        "outputId": "b47d9099-94b4-494e-ae5c-3223136339c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/178.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=060274f634bde9fdbbe037978b6618f86e89bfa3edb2a99f4b91cde43a40cbfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: [ WARN:0@90.610] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
        "# [ERROR:0@90.610] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
        "\n",
        "# Check if the camera is properly connected and accessible.\n",
        "!ls /dev/video*\n",
        "\n",
        "# If the camera is not detected, try the following:\n",
        "# - Make sure the camera is properly connected to the device.\n",
        "# - Check if the camera driver is installed and up-to-date.\n",
        "# - Try a different USB port or cable.\n",
        "# - If the issue persists, the camera might be faulty.\n",
        "\n",
        "# If the camera is detected, try the following:\n",
        "# - Update the OpenCV library.\n",
        "# - Try a different version of OpenCV.\n",
        "# - Use a different camera model.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHB5dFQNtM4",
        "outputId": "be2249e3-b2c9-4efc-e559-ba9d26b440a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/dev/video*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "how"
      ],
      "metadata": {
        "id": "3feXtfDpPU3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to push colab notebook o n github\n",
        "\n",
        "1. **Save the Colab notebook**:\n",
        "\n"
      ],
      "metadata": {
        "id": "58vceJsTPUnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}